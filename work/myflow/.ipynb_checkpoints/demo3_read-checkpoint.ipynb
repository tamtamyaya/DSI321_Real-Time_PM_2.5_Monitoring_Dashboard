{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: weather/main/weather.parquet/year=2025/month=5/day=13/\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "When getting information for key 'main/weather.parquet/year=2025/month=5/day=13' in bucket 'weather': AWS Error NETWORK_CONNECTION during HeadObject operation: curlCode: 6, Couldn't resolve host name",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Parquet\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m dataset = \u001b[43mpq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Schema ‡∏Ç‡∏≠‡∏á dataset\u001b[39;00m\n\u001b[32m     36\u001b[39m schema = dataset.schema\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/parquet/core.py:1338\u001b[39m, in \u001b[36mParquetDataset.__init__\u001b[39m\u001b[34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m   1337\u001b[39m         filesystem = LocalFileSystem(use_mmap=memory_map)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m finfo = \u001b[43mfilesystem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_file_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m finfo.type == FileType.Directory:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28mself\u001b[39m._base_dir = path_or_paths\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/_fs.pyx:588\u001b[39m, in \u001b[36mpyarrow._fs.FileSystem.get_file_info\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: When getting information for key 'main/weather.parquet/year=2025/month=5/day=13' in bucket 'weather': AWS Error NETWORK_CONNECTION during HeadObject operation: curlCode: 6, Couldn't resolve host name"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pyarrow import parquet as pq\n",
    "from pyarrow import fs\n",
    "\n",
    "# üîê lakeFS credentials\n",
    "ACCESS_KEY = \"access_key\"\n",
    "SECRET_KEY = \"secret_key\"\n",
    "lakefs_endpoint = \"http://lakefs-dev:8000/\"\n",
    "\n",
    "# ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ FileSystem ‡∏Ç‡∏≠‡∏á LakeFS\n",
    "s3 = fs.S3FileSystem(\n",
    "    access_key=ACCESS_KEY, \n",
    "    secret_key=SECRET_KEY, \n",
    "    endpoint_override=lakefs_endpoint\n",
    ")\n",
    "\n",
    "# ‚úÖ ‡∏£‡∏∞‡∏ö‡∏∏ Path ‡∏´‡∏•‡∏±‡∏Å\n",
    "base_path = 'weather/main/weather.parquet/year=2025/month=5/'\n",
    "\n",
    "# ‚úÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "days = [13, 14, 15]\n",
    "\n",
    "# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á List ‡πÄ‡∏Å‡πá‡∏ö DataFrame\n",
    "df_list = []\n",
    "\n",
    "# ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "for day in days:\n",
    "    path = f\"{base_path}day={day}/\"\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    \n",
    "    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Parquet\n",
    "    dataset = pq.ParquetDataset(path, filesystem=s3)\n",
    "    \n",
    "    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Schema ‡∏Ç‡∏≠‡∏á dataset\n",
    "    schema = dataset.schema\n",
    "    \n",
    "    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á Schema ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô float64 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô float32 ‡∏´‡∏£‡∏∑‡∏≠ int64\n",
    "    fields = []\n",
    "    for i in range(len(schema)):\n",
    "        field = schema.field(i)\n",
    "        if isinstance(field.type, pa.FloatArray) or field.type == pa.float32():\n",
    "            fields.append(pa.field(field.name, pa.float64()))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float64\n",
    "        elif field.type == pa.int64():  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏ô‡∏¥‡∏î int64\n",
    "            fields.append(pa.field(field.name, pa.float64()))  # ‡πÅ‡∏õ‡∏•‡∏á int64 ‡πÄ‡∏õ‡πá‡∏ô float64\n",
    "        else:\n",
    "            fields.append(field)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Schema ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å fields ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß\n",
    "    new_schema = pa.schema(fields)\n",
    "    \n",
    "    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "    try:\n",
    "        table = dataset.read().cast(new_schema)\n",
    "        df = table.to_pandas()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° DataFrame ‡∏•‡∏á‡πÉ‡∏ô List\n",
    "    df_list.append(df)\n",
    "\n",
    "# ‚úÖ ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å DataFrame ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "print(final_df.info())\n",
    "print(final_df.head())\n",
    "print(f\"Total Records Loaded: {len(final_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
